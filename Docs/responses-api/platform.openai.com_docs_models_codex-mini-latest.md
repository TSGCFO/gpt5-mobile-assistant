---
url: "https://platform.openai.com/docs/models/codex-mini-latest"
title: "Model - OpenAI API"
---

Log in [Sign up](https://platform.openai.com/signup)

[Models](https://platform.openai.com/docs/models)

![codex-mini-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/codex-mini-latest.png)

codex-mini-latest

Default

Fast reasoning model optimized for the Codex CLI

Fast reasoning model optimized for the Codex CLI

Compare

Performance

Higher

Speed

Medium

Price

$1.5 • $6

Input • Output

Input

Text, image

Output

Text

codex-mini-latest is a fine-tuned version of o4-mini specifically
for use in Codex CLI. For direct use in the API, we recommend starting
with gpt-4.1.

200,000 context window

100,000 max output tokens

Jun 01, 2024 knowledge cutoff

Reasoning token support

Pricing

Pricing is based on the number of tokens used. For tool-specific models, like search and computer use, there's a fee per tool call. See details in the [pricing page](https://platform.openai.com/docs/pricing).

Text tokens

Per 1M tokens

Input

$1.50

Cached input

$0.375

Output

$6.00

Quick comparison

Input

Cached input

Output

GPT-4.1

$2.00

codex-mini-latest

$1.50

o4-mini

$1.10

Modalities

Text

Input and output

Image

Input only

Audio

Not supported

Endpoints

Chat Completions

v1/chat/completions

Responses

v1/responses

Realtime

v1/realtime

Assistants

v1/assistants

Batch

v1/batch

Fine-tuning

v1/fine-tuning

Embeddings

v1/embeddings

Image generation

v1/images/generations

Image edit

v1/images/edits

Speech generation

v1/audio/speech

Transcription

v1/audio/transcriptions

Translation

v1/audio/translations

Moderation

v1/moderations

Completions (legacy)

v1/completions

Features

Streaming

Supported

Function calling

Supported

Structured outputs

Supported

Fine-tuning

Not supported

Distillation

Not supported

Predicted outputs

Not supported

Snapshots

Snapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for codex-mini-latest.

![codex-mini-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/codex-mini-latest.png)

codex-mini-latest

codex-mini-latest

codex-mini-latest

Rate limits

Rate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.

| Tier | RPM | TPM | Batch queue limit |
| --- | --- | --- | --- |
| Free | Not supported |
| Tier 1 | 1,000 | 100,000 | 1,000,000 |
| Tier 2 | 2,000 | 200,000 | 2,000,000 |
| Tier 3 | 5,000 | 4,000,000 | 40,000,000 |
| Tier 4 | 10,000 | 10,000,000 | 1,000,000,000 |
| Tier 5 | 30,000 | 150,000,000 | 15,000,000,000 |

We use cookies and similar technologies to deliver, maintain, improve our services and for security purposes. Check our [Cookie Policy](https://openai.com/policies/cookie-policy) for details. Click 'Accept all' to let OpenAI and partners use cookies for these purposes. Click 'Reject all' to say no to cookies, except those that are strictly necessary. Choose 'Manage Cookies' to pick specific cookies you're okay with or to change your preferences.

Reject allAccept all