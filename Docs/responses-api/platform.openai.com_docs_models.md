---
url: "https://platform.openai.com/docs/models"
title: "Models - OpenAI API"
---

Log in [Sign up](https://platform.openai.com/signup)

# Models

Explore all available models and compare their capabilities.

Compare models

Featured models

[GPT-5\\
\\
The best model for coding and agentic tasks across domains](https://platform.openai.com/docs/models/gpt-5) [GPT-5 mini\\
\\
A faster, cost-efficient version of GPT-5 for well-defined tasks](https://platform.openai.com/docs/models/gpt-5-mini) [GPT-5 nano\\
\\
Fastest, most cost-efficient version of GPT-5](https://platform.openai.com/docs/models/gpt-5-nano)

Frontier models

OpenAI's most advanced models, recommended for most tasks.

[![gpt-5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.png)\\
\\
GPT-5\\
\\
The best model for coding and agentic tasks across domains](https://platform.openai.com/docs/models/gpt-5) [![gpt-5-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-mini.png)\\
\\
GPT-5 mini\\
\\
A faster, cost-efficient version of GPT-5 for well-defined tasks](https://platform.openai.com/docs/models/gpt-5-mini) [![gpt-5-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-nano.png)\\
\\
GPT-5 nano\\
\\
Fastest, most cost-efficient version of GPT-5](https://platform.openai.com/docs/models/gpt-5-nano) [![gpt-4.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1.png)\\
\\
GPT-4.1\\
\\
Smartest non-reasoning model](https://platform.openai.com/docs/models/gpt-4.1)

Open-weight models

Open-weight models under a permissive Apache 2.0 license.

[![gpt-oss-120b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-120b.png)\\
\\
gpt-oss-120b\\
\\
Most powerful open-weight model, fits into an H100 GPU](https://platform.openai.com/docs/models/gpt-oss-120b) [![gpt-oss-20b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-20b.png)\\
\\
gpt-oss-20b\\
\\
Medium-sized open-weight model for low latency](https://platform.openai.com/docs/models/gpt-oss-20b)

Specialized models

Purpose-built for specific tasks.

[![o3-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-deep-research.png)\\
\\
o3-deep-research\\
\\
Our most powerful deep research model](https://platform.openai.com/docs/models/o3-deep-research) [![o4-mini-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini-deep-research.png)\\
\\
o4-mini-deep-research\\
\\
Faster, more affordable deep research model](https://platform.openai.com/docs/models/o4-mini-deep-research) [![gpt-image-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.png)\\
\\
GPT Image 1\\
\\
State-of-the-art image generation model](https://platform.openai.com/docs/models/gpt-image-1) [![dall-e-3](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-3.png)\\
\\
DALLÂ·E 3\\
\\
Previous generation image generation model](https://platform.openai.com/docs/models/dall-e-3) [![gpt-4o-mini-tts](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-tts.png)\\
\\
GPT-4o mini TTS\\
\\
Text-to-speech model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-tts) [![gpt-4o-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe.png)\\
\\
GPT-4o Transcribe\\
\\
Speech-to-text model powered by GPT-4o](https://platform.openai.com/docs/models/gpt-4o-transcribe) [![gpt-4o-mini-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-transcribe.png)\\
\\
GPT-4o mini Transcribe\\
\\
Speech-to-text model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-transcribe)

Realtime and audio models

Models for audio use cases and realtime inputs and outputs.

[![gpt-realtime](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime.png)\\
\\
gpt-realtime\\
\\
Model capable of realtime text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-realtime) [![gpt-audio](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio.png)\\
\\
gpt-audio\\
\\
For audio inputs and outputs with Chat Completions API](https://platform.openai.com/docs/models/gpt-audio)

ChatGPT models

Models used in ChatGPT, not recommended for API use.

[![gpt-5-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-chat-latest.png)\\
\\
GPT-5 Chat\\
\\
GPT-5 model used in ChatGPT](https://platform.openai.com/docs/models/gpt-5-chat-latest) [![chatgpt-4o-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-4o-latest.png)\\
\\
ChatGPT-4o\\
\\
GPT-4o model used in ChatGPT](https://platform.openai.com/docs/models/chatgpt-4o-latest)

All models

Diverse models for a variety of tasks.

[![gpt-5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.png)\\
\\
GPT-5\\
\\
The best model for coding and agentic tasks across domains](https://platform.openai.com/docs/models/gpt-5) [![gpt-5-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-mini.png)\\
\\
GPT-5 mini\\
\\
A faster, cost-efficient version of GPT-5 for well-defined tasks](https://platform.openai.com/docs/models/gpt-5-mini) [![gpt-5-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-nano.png)\\
\\
GPT-5 nano\\
\\
Fastest, most cost-efficient version of GPT-5](https://platform.openai.com/docs/models/gpt-5-nano) [![gpt-5-codex](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-codex.png)\\
\\
GPT-5-Codex\\
\\
A version of GPT-5 optimized for agentic coding in Codex](https://platform.openai.com/docs/models/gpt-5-codex) [![o3-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-deep-research.png)\\
\\
o3-deep-research\\
\\
Our most powerful deep research model](https://platform.openai.com/docs/models/o3-deep-research) [![o4-mini-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini-deep-research.png)\\
\\
o4-mini-deep-research\\
\\
Faster, more affordable deep research model](https://platform.openai.com/docs/models/o4-mini-deep-research) [![o3-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-pro.png)\\
\\
o3-pro\\
\\
Version of o3 with more compute for better responses](https://platform.openai.com/docs/models/o3-pro) [![gpt-audio](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio.png)\\
\\
gpt-audio\\
\\
For audio inputs and outputs with Chat Completions API](https://platform.openai.com/docs/models/gpt-audio) [![gpt-realtime](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime.png)\\
\\
gpt-realtime\\
\\
Model capable of realtime text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-realtime) [![o3](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3.png)\\
\\
o3\\
\\
Reasoning model for complex tasks, succeeded by GPT-5](https://platform.openai.com/docs/models/o3) [![o4-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini.png)\\
\\
o4-mini\\
\\
Fast, cost-efficient reasoning model, succeeded by GPT-5 mini](https://platform.openai.com/docs/models/o4-mini) [![gpt-4.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1.png)\\
\\
GPT-4.1\\
\\
Smartest non-reasoning model](https://platform.openai.com/docs/models/gpt-4.1) [![gpt-4.1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-mini.png)\\
\\
GPT-4.1 mini\\
\\
Smaller, faster version of GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1-mini) [![gpt-4.1-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-nano.png)\\
\\
GPT-4.1 nano\\
\\
Fastest, most cost-efficient version of GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1-nano) [![o1-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-pro.png)\\
\\
o1-pro\\
\\
Version of o1 with more compute for better responses](https://platform.openai.com/docs/models/o1-pro) [![computer-use-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/computer-use-preview.png)\\
\\
computer-use-preview\\
\\
Specialized model for computer use tool](https://platform.openai.com/docs/models/computer-use-preview) [![gpt-4o-mini-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-search-preview.png)\\
\\
GPT-4o mini Search Preview\\
\\
Fast, affordable small model for web search](https://platform.openai.com/docs/models/gpt-4o-mini-search-preview) [![gpt-4o-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-search-preview.png)\\
\\
GPT-4o Search Preview\\
\\
GPT model for web search in Chat Completions](https://platform.openai.com/docs/models/gpt-4o-search-preview) [![gpt-4.5-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.5-preview.png)\\
\\
GPT-4.5 Preview (Deprecated)\\
\\
Deprecated large model.](https://platform.openai.com/docs/models/gpt-4.5-preview) [![o3-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-mini.png)\\
\\
o3-mini\\
\\
A small model alternative to o3](https://platform.openai.com/docs/models/o3-mini) [![gpt-4o-mini-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-audio-preview.png)\\
\\
GPT-4o mini Audio\\
\\
Smaller model capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview) [![gpt-4o-mini-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-realtime-preview.png)\\
\\
GPT-4o mini Realtime\\
\\
Smaller realtime model for text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview) [![o1](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1.png)\\
\\
o1\\
\\
Previous full o-series reasoning model](https://platform.openai.com/docs/models/o1) [![omni-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/omni-moderation-latest.png)\\
\\
omni-moderation\\
\\
Identify potentially harmful content in text and images](https://platform.openai.com/docs/models/omni-moderation-latest) [![o1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-mini.png)\\
\\
o1-mini\\
\\
Deprecated\\
\\
A small model alternative to o1](https://platform.openai.com/docs/models/o1-mini) [![o1-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-preview.png)\\
\\
o1 Preview\\
\\
Deprecated\\
\\
Preview of our first o-series reasoning model](https://platform.openai.com/docs/models/o1-preview) [![gpt-4o](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o.png)\\
\\
GPT-4o\\
\\
Fast, intelligent, flexible GPT model](https://platform.openai.com/docs/models/gpt-4o) [![gpt-4o-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-audio-preview.png)\\
\\
GPT-4o Audio\\
\\
GPT-4o models capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-audio-preview) [![gpt-4o-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini.png)\\
\\
GPT-4o mini\\
\\
Fast, affordable small model for focused tasks](https://platform.openai.com/docs/models/gpt-4o-mini) [![gpt-4o-mini-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-audio-preview.png)\\
\\
GPT-4o mini Audio\\
\\
Smaller model capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview) [![gpt-4o-mini-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-realtime-preview.png)\\
\\
GPT-4o mini Realtime\\
\\
Smaller realtime model for text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview) [![gpt-4o-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-realtime-preview.png)\\
\\
GPT-4o Realtime\\
\\
Model capable of realtime text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-realtime-preview) [![gpt-4-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo.png)\\
\\
GPT-4 Turbo\\
\\
An older high-intelligence GPT model](https://platform.openai.com/docs/models/gpt-4-turbo) [![babbage-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/babbage-002.png)\\
\\
babbage-002\\
\\
Replacement for the GPT-3 ada and babbage base models](https://platform.openai.com/docs/models/babbage-002) [![chatgpt-4o-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-4o-latest.png)\\
\\
ChatGPT-4o\\
\\
GPT-4o model used in ChatGPT](https://platform.openai.com/docs/models/chatgpt-4o-latest) [![codex-mini-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/codex-mini-latest.png)\\
\\
codex-mini-latest\\
\\
Fast reasoning model optimized for the Codex CLI](https://platform.openai.com/docs/models/codex-mini-latest) [![dall-e-2](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-2.png)\\
\\
DALLÂ·E 2\\
\\
Our first image generation model](https://platform.openai.com/docs/models/dall-e-2) [![dall-e-3](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-3.png)\\
\\
DALLÂ·E 3\\
\\
Previous generation image generation model](https://platform.openai.com/docs/models/dall-e-3) [![davinci-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/davinci-002.png)\\
\\
davinci-002\\
\\
Replacement for the GPT-3 curie and davinci base models](https://platform.openai.com/docs/models/davinci-002) [![gpt-3.5-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-3.5-turbo.png)\\
\\
GPT-3.5 Turbo\\
\\
Legacy GPT model for cheaper chat and non-chat tasks](https://platform.openai.com/docs/models/gpt-3.5-turbo) [![gpt-4](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.png)\\
\\
GPT-4\\
\\
An older high-intelligence GPT model](https://platform.openai.com/docs/models/gpt-4) [![gpt-4-turbo-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo-preview.png)\\
\\
GPT-4 Turbo Preview\\
\\
An older fast GPT model](https://platform.openai.com/docs/models/gpt-4-turbo-preview) [![gpt-4o-mini-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-transcribe.png)\\
\\
GPT-4o mini Transcribe\\
\\
Speech-to-text model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-transcribe) [![gpt-4o-mini-tts](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-tts.png)\\
\\
GPT-4o mini TTS\\
\\
Text-to-speech model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-tts) [![gpt-4o-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe.png)\\
\\
GPT-4o Transcribe\\
\\
Speech-to-text model powered by GPT-4o](https://platform.openai.com/docs/models/gpt-4o-transcribe) [![gpt-5-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-chat-latest.png)\\
\\
GPT-5 Chat\\
\\
GPT-5 model used in ChatGPT](https://platform.openai.com/docs/models/gpt-5-chat-latest) [![gpt-image-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.png)\\
\\
GPT Image 1\\
\\
State-of-the-art image generation model](https://platform.openai.com/docs/models/gpt-image-1) [![gpt-oss-120b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-120b.png)\\
\\
gpt-oss-120b\\
\\
Most powerful open-weight model, fits into an H100 GPU](https://platform.openai.com/docs/models/gpt-oss-120b) [![gpt-oss-20b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-20b.png)\\
\\
gpt-oss-20b\\
\\
Medium-sized open-weight model for low latency](https://platform.openai.com/docs/models/gpt-oss-20b) [![text-embedding-3-large](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-large.png)\\
\\
text-embedding-3-large\\
\\
Most capable embedding model](https://platform.openai.com/docs/models/text-embedding-3-large) [![text-embedding-3-small](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-small.png)\\
\\
text-embedding-3-small\\
\\
Small embedding model](https://platform.openai.com/docs/models/text-embedding-3-small) [![text-embedding-ada-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-ada-002.png)\\
\\
text-embedding-ada-002\\
\\
Older embedding model](https://platform.openai.com/docs/models/text-embedding-ada-002) [![text-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-latest.png)\\
\\
text-moderation\\
\\
Deprecated\\
\\
Previous generation text-only moderation model](https://platform.openai.com/docs/models/text-moderation-latest) [![text-moderation-stable](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-stable.png)\\
\\
text-moderation-stable\\
\\
Deprecated\\
\\
Previous generation text-only moderation model](https://platform.openai.com/docs/models/text-moderation-stable) [![tts-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1.png)\\
\\
TTS-1\\
\\
Text-to-speech model optimized for speed](https://platform.openai.com/docs/models/tts-1) [![tts-1-hd](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1-hd.png)\\
\\
TTS-1 HD\\
\\
Text-to-speech model optimized for quality](https://platform.openai.com/docs/models/tts-1-hd) [![whisper-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/whisper-1.png)\\
\\
Whisper\\
\\
General-purpose speech recognition model](https://platform.openai.com/docs/models/whisper-1)

[How we use your data](https://platform.openai.com/docs/guides/your-data)Â· [Deprecated models](https://platform.openai.com/docs/deprecations)